{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python2.7/site-packages/pandas/computation/__init__.py:19: UserWarning: The installed version of numexpr 2.4.4 is not supported in pandas and will be not be used\n",
      "\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import zipfile\n",
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def shape2topojson (src, trg):\n",
    "\n",
    "    #unzip file\n",
    "    src_zip = src + \"SWE_adm_shp.zip\"\n",
    "    tmp_dir = \"tmp/\"\n",
    "    with zipfile.ZipFile(src_zip, \"r\") as z:\n",
    "        z.extractall(tmp_dir)\n",
    "        \n",
    "    #convert from shape to geojson\n",
    "    tmp_outfiles = [\"counties.json\", \"municipalities.json\"]\n",
    "    tmp_infiles = [\"SWE_adm1.shp\", \"SWE_adm2.shp\"]\n",
    "    cmd = \"ogr2ogr -f GeoJSON \"\n",
    "    \n",
    "    for i in range(len(tmp_infiles)):\n",
    "        command = cmd + tmp_dir + tmp_outfiles[i] + \" \" + tmp_dir + tmp_infiles[i]\n",
    "        print \"Running command \" + command\n",
    "        subprocess.call(command, shell=True)\n",
    "    \n",
    "    #convert from geosjon to topojson\n",
    "    cmd = \"topojson -o \"\n",
    "    tmp_outfile = trg + \"sweden.json\"\n",
    "    tmp_args = \" --id-property HASC_2,HASC_1 -p municipality_name=NAME_2,county_name=NAME_1 -- \"\n",
    "    command = cmd + tmp_outfile + tmp_args + \" \".join([tmp_dir + tmp_outfile for tmp_outfile in tmp_outfiles])\n",
    "    print \"Running command \" + command\n",
    "    subprocess.call(command, shell=True)\n",
    "    \n",
    "    #create id files\n",
    "    df = pd.read_csv(tmp_dir + \"SWE_adm1.csv\", encoding=\"utf-8\", usecols=[\"NAME_1\",\"HASC_1\"])\n",
    "    df.rename(columns = {\"NAME_1\": \"county\", \"HASC_1\": \"domID\"}, inplace=True)\n",
    "    df[\"county\"] = df[\"county\"].str.upper()\n",
    "    df[\"domID\"] = map(lambda x: \"-\".join(x.split(\".\")), df[\"domID\"])\n",
    "    df.to_csv(trg + \"domID-county.csv\", index=False, encoding=\"utf-8\")\n",
    "    \n",
    "    df = pd.read_csv(tmp_dir + \"SWE_adm2.csv\", encoding=\"utf-8\", usecols=[\"NAME_2\",\"HASC_2\"])\n",
    "    df.rename(columns = {\"NAME_2\": \"municipality\", \"HASC_2\": \"domID\"}, inplace=True)\n",
    "    df[\"municipality\"] = df[\"municipality\"].str.upper()\n",
    "    df = df.fillna(\"SE.VG.ML\")\n",
    "    df = df.set_index(\"municipality\")\n",
    "    df.loc[\"KNIVSTA\"] = \"SE.UP.KN\"\n",
    "    df = df.reset_index()\n",
    "    df[\"domID\"] = map(lambda x: \"-\".join(x.split(\".\")), df[\"domID\"])\n",
    "    df.to_csv(trg + \"domID-municipality.csv\", index=False, encoding=\"utf-8\")\n",
    "    \n",
    "    del df\n",
    "    \n",
    "    #delete tmp dir\n",
    "    shutil.rmtree(tmp_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running command ogr2ogr -f GeoJSON tmp/counties.json tmp/SWE_adm1.shp\n",
      "Running command ogr2ogr -f GeoJSON tmp/municipalities.json tmp/SWE_adm2.shp\n",
      "Running command topojson -o output/sweden.json --id-property HASC_2,HASC_1 -p municipality_name=NAME_2,county_name=NAME_1 -- tmp/counties.json tmp/municipalities.json\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    #Extract geo data\n",
    "    shape2topojson (\"src/\", \"output/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## paths and filenames\n",
    "\n",
    "src = \"src/\"\n",
    "trg = \"output/\"\n",
    "\n",
    "rec = src + \"Kommunmottagna+enligt+ersattningsförordningen+2015.xls\"\n",
    "asylum_applications = src + \"Inkomna+ansökningar+om+asyl+2015+-+Applications+for+asylum+received+2015.xls\"\n",
    "asylum_granted = src + \"Avgjorda+asylärenden+2015+-+Asylum+desicions+2015.xls\"\n",
    "trans = src + \"translation.xlsx\"\n",
    "pop_county = src + \"BE0101N1_county.xlsx\"\n",
    "pop_municipality = src + \"BE0101N1_municipality.xlsx\"\n",
    "ids_county = trg + \"domID-county.csv\"\n",
    "ids_muni = trg + \"domID-municipality.csv\"\n",
    "income_county = src + \"HE0110J8_county.xlsx\"\n",
    "opinion = src + \"opinion.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# translation\n",
    "df_translation = pd.read_excel(trans)\n",
    "translation = pd.Series(df_translation.new.values,index=df_translation.old).to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Asylum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing output/asylum.csv\n"
     ]
    }
   ],
   "source": [
    "# asylum data\n",
    "df_applications = pd.read_excel(asylum_applications, sheetname=0, \\\n",
    "                                skiprows=[0,1,2,3,4,5], parse_cols=\"B:G\", skip_footer=4, index_col=0)\n",
    "df_granted = pd.read_excel(asylum_granted, sheetname=0, \\\n",
    "                           skiprows=[0,1,2,3,4,5,6,7,8], parse_cols=\"B,D:L\", skip_footer=6, index_col=0)\n",
    "\n",
    "df_merged = pd.concat([df_applications, df_granted], axis=1)\n",
    "df_merged = df_merged.reset_index()\n",
    "df_merged[\"deficit\"] = df_merged[\"Number\"] - df_merged[\"Decisions\"]\n",
    "\n",
    "outfile = trg + \"asylum.csv\"\n",
    "df_merged.to_csv(outfile, index=False, encoding=\"utf-8\")\n",
    "print \"Printing \" + outfile\n",
    "\n",
    "del df_applications\n",
    "del df_granted\n",
    "del df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[29.0, 14.0, 9.0, 7.0, 5.0, 4.0, 4.0, 3.0, 3.0, 2.0, 2.0, 2.0, 2.0, 2.0, 1.0]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wh = 1812 #working hours per year\n",
    "h = 247 #handling time\n",
    "c = 1812 / 247 # cases per year and employee\n",
    "D = 104075 # deficit at end of 2015\n",
    "\n",
    "employees = [500,1000,1500,2000,2500,3000,3500,4000,4500,5000,5500,6000,6500,7000,7500]\n",
    "y = [np.ceil(D/(c*x)) for x in employees]\n",
    "\n",
    "#data = {\"employees\": employees, \"years_left\": y}\n",
    "#df_deficit = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing output/asylum-coo.csv\n"
     ]
    }
   ],
   "source": [
    "# applications by country of origin\n",
    "df_applications_coo = pd.read_excel(asylum_applications, sheetname=1, skiprows=[0,1,2,3,4,5,6,7,8,9], parse_cols=\"B,D:H\")\n",
    "df_applications_coo = df_applications_coo.fillna(0);\n",
    "df_applications_coo = df_applications_coo.sort_values(\"Number\", ascending=False);\n",
    "\n",
    "outfile = trg + \"asylum-coo.csv\"\n",
    "df_applications_coo.to_csv(outfile, index=False, encoding=\"utf-8\")\n",
    "print \"Printing \" + outfile\n",
    "\n",
    "del df_applications_coo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing output/asylum-coo-granted.csv\n"
     ]
    }
   ],
   "source": [
    "# granted applications by country of origin\n",
    "df_apps_granted_coo = pd.read_excel(asylum_granted, sheetname=1, skiprows=[0,1,2,3,4,5,6,7,8], parse_cols=\"B,D:L\")\n",
    "\n",
    "\n",
    "df_apps_granted_coo.iloc[df_apps_granted_coo.count()[0],0] = \"Total\"\n",
    "df_apps_granted_coo = df_apps_granted_coo.fillna(0)\n",
    "df_apps_granted_coo = df_apps_granted_coo.sort_values(\"of which granted\", ascending=False)\n",
    "df_apps_granted_coo = df_apps_granted_coo.rename(columns={\" Citizenship\": \"Citizenship\"})\n",
    "\n",
    "outfile = trg + \"asylum-coo-granted.csv\"\n",
    "df_apps_granted_coo.to_csv(outfile, index=False, encoding=\"utf-8\")\n",
    "print \"Printing \" + outfile\n",
    "\n",
    "del df_apps_granted_coo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arrivals "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing output/arrivals-reason.csv\n"
     ]
    }
   ],
   "source": [
    "# refugees received by reason\n",
    "df_rec_reason = pd.read_excel(rec, sheetname=5, skiprows=[0,1,2,3,4,5], parse_cols=\"B,D:P\")\n",
    "\n",
    "# rename columns\n",
    "df_rec_reason.rename(columns = {\"Unnamed: 0\": \"county\", \"Unnamed: 1\": \"municipality\"}, inplace=True)\n",
    "df_rec_reason.rename(columns = translation, inplace=True)\n",
    "\n",
    "# fix missing values\n",
    "df_rec_reason = df_rec_reason.dropna(axis=0,how=\"all\")\n",
    "df_rec_reason = pd.concat([df_rec_reason.loc[:,df_rec_reason.columns[:2]].fillna(\"\"), \\\n",
    "                         df_rec_reason.loc[:,df_rec_reason.columns[2:]].fillna(0)], axis=1)\n",
    "\n",
    "outfile = trg + \"arrivals-reason.csv\"\n",
    "df_rec_reason.to_csv(outfile, index=False, encoding=\"utf-8\")\n",
    "print \"Printing \" + outfile\n",
    "\n",
    "del df_rec_reason"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing output/arrivals-age.csv\n"
     ]
    }
   ],
   "source": [
    "# refugees received by age\n",
    "df_rec_age = pd.read_excel(rec, sheetname=6, skiprows=[0,1,2,3,4,5], parse_cols=\"B,D:N\")\n",
    "\n",
    "# rename columns\n",
    "df_rec_age.rename(columns = {\"Unnamed: 0\": \"county\", \"Unnamed: 1\": \"municipality\"}, inplace=True)\n",
    "df_rec_age.rename(columns = translation, inplace=True)\n",
    "\n",
    "# fix missing values\n",
    "df_rec_age = df_rec_age.dropna(axis=0,how=\"all\")\n",
    "df_rec_age = pd.concat([df_rec_age.loc[:,df_rec_age.columns[:2]].fillna(\"\"), \\\n",
    "                         df_rec_age.loc[:,df_rec_age.columns[2:]].fillna(0)], axis=1)\n",
    "\n",
    "outfile = trg + \"arrivals-age.csv\"\n",
    "df_rec_age.to_csv(outfile, index=False, encoding=\"utf-8\")\n",
    "print \"Printing \" + outfile\n",
    "\n",
    "del df_rec_age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing output/arrivals-citizenship-full.csv\n"
     ]
    }
   ],
   "source": [
    "# refugees received by citizenship\n",
    "df_rec_coo = pd.read_excel(rec, sheetname=7, skiprows=[0,1,2,3,4,5], parse_cols=\"B:O\")\n",
    "\n",
    "# rename columns\n",
    "df_rec_coo.rename(columns = {\"Unnamed: 0\": \"county\", \"Unnamed: 1\": \"citizenship\"}, inplace=True)\n",
    "df_rec_coo.rename(columns = translation, inplace=True)\n",
    "\n",
    "# fix missing values\n",
    "df_rec_coo = df_rec_coo.dropna(axis=0,how=\"all\")\n",
    "df_rec_coo = pd.concat([df_rec_coo.loc[:,df_rec_coo.columns[:2]].fillna(\"\"), \\\n",
    "                         df_rec_coo.loc[:,df_rec_coo.columns[2:]].fillna(0)], axis=1)\n",
    "\n",
    "outfile = trg + \"arrivals-citizenship-full.csv\"\n",
    "df_rec_coo.to_csv(outfile, index=False, encoding=\"utf-8\")\n",
    "print \"Printing \" + outfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing output/arrivals-citizenship.csv\n"
     ]
    }
   ],
   "source": [
    "# refugees received by citizenship\n",
    "df_rec_citizenship = pd.read_excel(rec, sheetname=7, skiprows=[0,1,2,3,4,5], parse_cols=\"B,C,N,O\")\n",
    "\n",
    "# rename columns\n",
    "df_rec_citizenship.rename(columns = {\"Unnamed: 0\": \"county\", \"Unnamed: 1\": \"citizenship\"}, inplace=True)\n",
    "df_rec_citizenship.rename(columns = translation, inplace=True)\n",
    "\n",
    "# get unique counties and countries\n",
    "countries = df_rec_citizenship[\"citizenship\"].dropna().unique()\n",
    "\n",
    "idx = []\n",
    "idx.append(np.where(countries == \"Totalt\")[0][0])\n",
    "idx.append(np.where(countries == \"Delsumma\")[0][0])\n",
    "countries = np.delete(countries, idx)\n",
    "counties = df_rec_citizenship[\"county\"].unique()\n",
    "\n",
    "# create new dataframe\n",
    "header = np.insert(countries[:-1], 0, \"county\")\n",
    "df_rec_citizenship = pd.DataFrame(columns = header)\n",
    "df_rec_citizenship[\"county\"] = counties\n",
    "df_rec_citizenship = df_rec_citizenship.dropna(axis=0,how=\"all\")\n",
    "df_rec_citizenship = df_rec_citizenship.set_index(\"county\")\n",
    "\n",
    "county = \"\"\n",
    "country = \"\"\n",
    "value = 0\n",
    "for index, row in df_rec_coo.iterrows():\n",
    "    if (row[\"county\"] and county != row[\"county\"]):\n",
    "        county = row[\"county\"]\n",
    "    \n",
    "    if (row[\"citizenship\"] != \"Delsumma\" and row[\"citizenship\"] != \"Totalt\"):\n",
    "        country = row[\"citizenship\"]\n",
    "        value = row[\"total\"]\n",
    "        df_rec_citizenship.loc[county,country] = value\n",
    "\n",
    "# fill nans and unset index\n",
    "df_rec_citizenship = df_rec_citizenship.fillna(0).reset_index()\n",
    "\n",
    "outfile = trg + \"arrivals-citizenship.csv\"\n",
    "df_rec_citizenship.to_csv(outfile, index=False, encoding=\"utf-8\")\n",
    "print \"Printing \" + outfile\n",
    "\n",
    "del df_rec_coo\n",
    "del df_rec_citizenship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# refugees received per capita\n",
    "df_rec = pd.read_excel(rec, sheetname=5, skiprows=[0,1,2,3,4,5], parse_cols=\"B,D,O\")\n",
    "df_pop = pd.read_excel(pop_county, skiprows=[0,1], skip_footer=40,parse_cols=\"A:C\", \\\n",
    "                       converters={'Unnamed: 0': lambda x: str(x)});\n",
    "df_pop_muni = pd.read_excel(pop_municipality, skiprows=[0,1], skip_footer=40,parse_cols=\"A:C\", \\\n",
    "                       converters={'Unnamed: 0': lambda x: str(x)});\n",
    "\n",
    "# rename\n",
    "df_rec.rename(columns = {\"Unnamed: 0\": \"county\", \"Unnamed: 1\": \"municipality\"}, inplace=True)\n",
    "df_rec.rename(columns = translation, inplace=True)\n",
    "df_rec.rename(columns = {\"total\": \"received\"}, inplace=True)\n",
    "df_rec = df_rec.dropna(axis=0,how=\"all\")\n",
    "df_pop.rename(columns = {\"Unnamed: 0\": \"code\", \"Unnamed: 1\": \"county\", \"2015\": \"total\"}, inplace=True)\n",
    "df_pop_muni.rename(columns = {\"Unnamed: 0\": \"code\", \"Unnamed: 1\": \"municipality\", \"2015\": \"total\"}, inplace=True)\n",
    "\n",
    "# get only county and total, make county names uppercase\n",
    "df_rec_muni = df_rec[df_rec.loc[:,\"municipality\"] != \"Delsumma\"][[\"municipality\",\"received\"]]\n",
    "df_rec_muni = df_rec_muni[df_rec_muni.loc[:,\"municipality\"] != \"Totalt\"]\n",
    "df_rec = df_rec[df_rec.loc[:,\"municipality\"] == \"Delsumma\"][[\"county\",\"received\"]]\n",
    "df_pop[\"county\"] = df_pop[\"county\"].str.upper()\n",
    "df_pop_muni[\"municipality\"] = df_pop_muni[\"municipality\"].str.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing output/arrivals-pc-county.csv\n",
      "Printing output/arrivals-pc-municipality.csv\n"
     ]
    }
   ],
   "source": [
    "df_rec_pc = df_pop.set_index(\"county\")\n",
    "df_rec_pc_muni = df_pop_muni.set_index(\"municipality\")\n",
    "df_rec_pc[\"received\"] = 0\n",
    "df_rec_pc_muni[\"received\"] = 0\n",
    "county = \"\"\n",
    "municipality = \"\"\n",
    "\n",
    "for index, row in df_rec.iterrows():\n",
    "    county = row[\"county\"]\n",
    "    value = row[\"received\"]\n",
    "    df_rec_pc.loc[county,\"received\"] = value\n",
    "    \n",
    "for index, row in df_rec_muni.iterrows():\n",
    "    municipality = row[\"municipality\"]\n",
    "    value = row[\"received\"]\n",
    "    if (municipality in df_rec_pc_muni.index):\n",
    "        df_rec_pc_muni.loc[municipality, \"received\"] = value\n",
    "    else:\n",
    "        df_rec_pc_muni.loc[municipality.replace(\"-\", \" \"), \"received\"] = value\n",
    "\n",
    "# add column for percentage and reorder cols\n",
    "df_rec_pc = df_rec_pc.reset_index()\n",
    "df_rec_pc[\"percent\"] = df_rec_pc[\"received\"] / df_rec_pc[\"total\"]\n",
    "df_rec_pc = df_rec_pc[[\"code\",\"county\",\"percent\",\"received\",\"total\"]]\n",
    "\n",
    "df_rec_pc_muni = df_rec_pc_muni.reset_index()\n",
    "df_rec_pc_muni[\"percent\"] = df_rec_pc_muni[\"received\"] / df_rec_pc_muni[\"total\"]\n",
    "df_rec_pc_muni = df_rec_pc_muni[[\"code\",\"municipality\",\"percent\",\"received\",\"total\"]]\n",
    "\n",
    "# add domIDs\n",
    "df_ids = pd.read_csv(ids_county, encoding=\"utf-8\")\n",
    "df_ids = df_ids.set_index(\"county\")\n",
    "df_rec_pc = df_rec_pc.set_index(\"county\")\n",
    "df_rec_pc[\"domID\"] = \"\"\n",
    "\n",
    "df_ids_muni = pd.read_csv(ids_muni, encoding=\"utf-8\")\n",
    "df_ids_muni = df_ids_muni.set_index(\"municipality\")\n",
    "df_rec_pc_muni = df_rec_pc_muni.set_index(\"municipality\")\n",
    "df_rec_pc_muni[\"domID\"] = \"\" \n",
    "\n",
    "# counties\n",
    "for index, row in df_rec_pc.iterrows():\n",
    "    county = index\n",
    "    county = \" \".join(county.split(\" \")[:-1])\n",
    "    if county[-1] == \"S\":\n",
    "        county = county[:-1]\n",
    "        \n",
    "    if (county in df_ids.index):\n",
    "        value = df_ids.loc[county].domID\n",
    "        df_rec_pc.loc[index, \"domID\"] = value\n",
    "        \n",
    "df_rec_pc = df_rec_pc.reset_index()\n",
    "df_rec_pc = df_rec_pc.set_index(\"code\")\n",
    "df_rec_pc.loc[\"18\",\"domID\"] = \"SE-OR\" # fix örebro\n",
    "df_rec_pc = df_rec_pc.reset_index()\n",
    "\n",
    "# municipalities\n",
    "for index, row in df_rec_pc_muni.iterrows():\n",
    "    municipality = index\n",
    "    if (municipality in df_ids_muni.index):\n",
    "        value = df_ids_muni.loc[municipality].domID\n",
    "        df_rec_pc_muni.loc[index, \"domID\"] = value\n",
    "\n",
    "df_rec_pc_muni = df_rec_pc_muni.reset_index()\n",
    "df_rec_pc_muni = df_rec_pc_muni.set_index(\"code\")\n",
    "df_rec_pc_muni.loc[\"0114\", \"domID\"] = \"SE-ST-UV\"\n",
    "df_rec_pc_muni.loc[\"2023\", \"domID\"] = \"SE-KO-MA\"\n",
    "df_rec_pc_muni = df_rec_pc_muni.reset_index()\n",
    "        \n",
    "outfile = trg + \"arrivals-pc-county.csv\"\n",
    "df_rec_pc.to_csv(outfile, index=False, encoding=\"utf-8\")\n",
    "print \"Printing \" + outfile\n",
    "\n",
    "outfile = trg + \"arrivals-pc-municipality.csv\"\n",
    "df_rec_pc_muni.to_csv(outfile, index=False, encoding=\"utf-8\")\n",
    "print \"Printing \" + outfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del df_rec\n",
    "del df_rec_muni\n",
    "del df_pop\n",
    "del df_pop_muni\n",
    "del df_rec_pc\n",
    "del df_rec_pc_muni\n",
    "del df_ids\n",
    "del df_ids_muni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing output/median-income-arrivals-county.csv\n"
     ]
    }
   ],
   "source": [
    "# get median income per month\n",
    "df_income_county = pd.read_excel(income_county, skiprows=[0,1], skip_footer=31,parse_cols=\"A,B,E\", \\\n",
    "                       converters={'Unnamed: 0': lambda x: str(x)});\n",
    "\n",
    "df_arrivals_county = pd.read_csv(trg + \"arrivals-pc-county.csv\")\n",
    "\n",
    "df_income_county.rename(columns = {\"Unnamed: 0\": \"code\", \"Unnamed: 1\": \"county\", \"2014\": \"income\"}, inplace=True)\n",
    "df_income_county[\"income\"] = df_income_county[\"income\"] * 1000 / 12\n",
    "df_income_county[\"county\"] = df_income_county[\"county\"].str.upper()\n",
    "df_income_county[\"arrivals\"] = df_arrivals_county[\"received\"]\n",
    "\n",
    "outfile = trg + \"median-income-arrivals-county.csv\"\n",
    "df_income_county.to_csv(outfile, index=False, encoding=\"utf-8\")\n",
    "print \"Printing \" + outfile\n",
    "\n",
    "del df_income_county"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing output/opinion.csv\n"
     ]
    }
   ],
   "source": [
    "# fix opinion\n",
    "df_opinion = pd.read_csv(opinion)\n",
    "df_opinion.rename(columns = translation, inplace=True)\n",
    "\n",
    "outfile = trg + \"opinion.csv\"\n",
    "df_opinion.to_csv(outfile, index=False, encoding=\"utf-8\")\n",
    "print \"Printing \" + outfile"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
